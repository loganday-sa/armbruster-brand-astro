# High-Risk AI: Pre-Deployment Compliance Checklist

**Purpose:** Visual checklist of 8 mandatory requirements before launching high-risk AI systems

**Visual Style:** Checklist with icons, regulatory citations, and status indicators

---

## Checklist Header
**Context:** "If your AI makes decisions about hiring, lending, healthcare, law enforcement, education, or essential services—this checklist is mandatory."

**Penalty Warning:** "EU fines up to €35M or 7% global revenue | Colorado up to $20K per violation"

---

## Requirement 1: Impact Assessment ✓
**Icon:** Document with risk matrix

**What It Is:** Pre-deployment assessment documenting intended use, potential harms, mitigation strategies

**Must Include:**
- System description and decision-making role
- Data sources and training data details
- Reasonably foreseeable risks of harm
- Risk mitigation measures
- Affected demographic groups analysis
- Human oversight mechanisms

**Regulations:** Colorado SB 24-205 | EU AI Act Article 27

**Status Indicator:** [ ] Complete before deployment

---

## Requirement 2: Bias Audit ✓
**Icon:** Balance scale / Fairness symbol

**What It Is:** Independent or internal audit testing for discriminatory outcomes across protected classes

**Must Include:**
- Disparate impact analysis (race, gender, age)
- Selection rate ratios published (NYC requirement)
- Confusion matrix by demographic group
- Statistical significance testing
- Audit methodology documentation

**Regulations:** NYC Local Law 144 (annual) | EU AI Act (before deployment + major changes)

**Status Indicator:** [ ] Complete within last 12 months

---

## Requirement 3: Technical Documentation ✓
**Icon:** Blueprint / Technical diagram

**What It Is:** Comprehensive documentation of system design, training, testing, and performance

**Must Include:**
- System architecture and design specs
- Training data description and methodology
- Model performance metrics
- Validation and testing results
- Known limitations and failure modes
- Cybersecurity measures
- Change log and version control

**Regulations:** EU AI Act Annex IV

**Retention:** 10 years (EU) | 3-7 years (US, varies by sector)

**Status Indicator:** [ ] Documentation package complete and stored

---

## Requirement 4: Model Card ✓
**Icon:** ID card / Information card

**What It Is:** Standardized documentation format for ML model details, intended use, and limitations

**Must Include:**
- Model details (version, type, license)
- Intended use and out-of-scope uses
- Performance metrics by subgroup
- Training and evaluation data description
- Ethical considerations
- Caveats and recommendations

**Regulations:** Best practice (not legally required but recommended)

**Status Indicator:** [ ] Model card published internally

---

## Requirement 5: Human Oversight ✓
**Icon:** Human figure with control panel

**What It Is:** Mechanism for human review and intervention in AI decisions

**Acceptable Models:**
- Human-in-the-loop (approves each decision)
- Human-on-the-loop (monitors and can intervene)
- Human-in-command (can override or shut down)

**Must Document:**
- Which oversight model is used and why
- Who has oversight authority
- Intervention triggers
- Escalation procedures

**Regulations:** GDPR Article 22 | EU AI Act

**Status Indicator:** [ ] Oversight mechanism active

---

## Requirement 6: Logging & Audit Trails ✓
**Icon:** Server logs / Database

**What It Is:** Automated logging enabling traceability of AI decisions

**Must Log:**
- Input data for each decision
- Model output and confidence scores
- Timestamp and system version
- User who invoked the model
- Human override events
- Errors and edge cases

**Retention:** 3-10 years (varies by regulation)

**Regulations:** EU AI Act Article 12

**Status Indicator:** [ ] Logging active and tamper-proof

---

## Requirement 7: Transparency Disclosures ✓
**Icon:** Megaphone / Announcement

**What It Is:** User-facing notice that AI is being used and how to contest decisions

**Must Disclose:**
- Clear notice AI is making/assisting decisions
- Purpose and general logic of the system
- Right to contest or request human review
- Contact for questions or complaints

**Example:** "This employer uses AI to screen resumes. An independent bias audit was conducted on [date]. You may request an alternative process at [email]."

**Regulations:** GDPR | NYC Local Law 144 | California AB 2930

**Status Indicator:** [ ] Disclosures published and accessible

---

## Requirement 8: Monitoring Plan ✓
**Icon:** Radar / Monitoring dashboard

**What It Is:** Post-deployment continuous monitoring plan for performance and bias

**Must Include:**
- Performance metrics tracked
- Drift detection (data and concept drift)
- Bias metrics tracked over time
- Incident reporting procedures
- Review cadence (monthly/quarterly)
- Triggers for re-audit

**Re-audit Triggers:**
- Performance degradation
- User complaints exceed threshold
- Substantial model modification
- Annual review

**Regulations:** EU AI Act Article 61

**Status Indicator:** [ ] Monitoring plan active

---

## Visual Design Notes:

**Layout:** Vertical checklist with 8 numbered items

**For Each Item Include:**
- Checkbox (large, prominent)
- Requirement number and title
- Icon representing the requirement
- "What It Is" brief description
- "Must Include" bullets (3-5 items)
- Regulatory citation
- Status indicator

**Color System:**
- Unchecked items: Orange/Red (urgent)
- Checked items: Green (compliant)
- Regulatory citations: Blue text

**Title:** "High-Risk AI: The 8-Step Compliance Checklist"

**Subtitle:** "All 8 must be complete before deployment in regulated markets"

**Footer:** "Scott Armbruster | AI Compliance Consulting"

**Warning Box:** "One missing requirement = non-compliant. The cost of getting this wrong isn't just fines—it's reputational damage, lawsuits, and rebuilding trust."

**CTA:** "Need help completing this checklist? Schedule a compliance consultation."
